from pathlib import Path
from typing import List

from exchange import Message, Exchange
from exchange.providers import OpenAiProvider

from goose.toolkit import Toolkit
from goose.toolkit.base import tool
from goose.toolkit.summarization.utils import summarize_file
from goose.utils.ask import ask_an_ai, clear_exchange
import PyPDF2


class O1Plan(Toolkit):
    """Make a plan for a project using gpt-o1"""

    # ideas to try:
    # - let goose inject the relevant context into the prompt
    # - make the developer toolkit a requirement for this toolkit to share state between the two
    # - modify the session core loop to allow for multiple exchanges between the goose agent and o1

    def system(self):
        return Message.load("prompts/o1_plan.jinja").text

    @tool
    def create_plan_with_o1(self, user_input: str, related_context: str = "", relevant_files: List[str] = []) -> str:
        """This tool generates a plan for a project using the GPT-O1 model.

        Args:
            user_input (str): The user's input about the project.
            related_context (Optional[str]): Any additional context related to the project submitted by the user.
            relevant_files (Optional[List[str]]): A list of relevant files that can be used to provide context to the model.

        Returns:
            o1_plam (str): The plan generated by the GPT-O1 model.
        """

        # would be nice if goose could open files already to inject the related context into the prompt
        # i think the best way to do this is to have goose open the file and then pass the text to the toolkit, but
        # i'm not sure how to do that yet


        # TODO: use the exchange_view (be sure to clear tools) instead of creating a new exchange
        provider = OpenAiProvider.from_env()
        accelerator = Exchange(provider=provider, model="gpt-4o-mini", system="")

        if relevant_files:
            # open each file and append to the related context (high likelihood this can really push the context window over the limit -- consider summarizing the files)
            for file in relevant_files:
                # path, summary = summarize_file(file, accelerator, prompt="Please summarize this paper.")
                # related_context += summary
                with open(file, "r") as f:
                    related_context += f.read()

        # give o1 some context of the project -- right now I hardcoded it in to include a summary of goose if it exists
        # ideally we call `repo_context` method here to get the context of the current project
        if Path("../../../.goose/summaries/goose-public-summary.json").exists():
            with open("../../../.goose/summaries/goose-public-summary.json") as f:
                project_summary = f.read()
        else:
            project_summary = ""

        # use the project summary and related context to create the system prompt for o1
        kwargs = {"project_summary": project_summary, "related_context": related_context}
        system = Message.load("prompts/o1_plan.jinja", **kwargs).text

        provider = OpenAiProvider.from_env()  # this is necessary as we can't really use the o1 model as the processor/accelerator
        o1_exchange = Exchange(provider=provider, model="o1-preview", system=system)

        # tell o1 what you want to code up / do -- this is the user prompt
        problem = user_input

        # o1 will respond -- the response is the plan
        response = ask_an_ai(input=problem, exchange=o1_exchange)

        # take the response from o1 and convert it into something that can be used as a plan
        return response.content[0].text


